#!/usr/bin/env python3
"""
Bing æœç´¢æ¨¡å—

ä½¿ç”¨ Bing Search è¿›è¡Œç½‘ç»œæœç´¢
"""

import os
import sys
import json
import argparse
import requests
import base64
from typing import Optional, Dict, Any, List
from urllib.parse import urlparse, parse_qs
from lxml import html
from dotenv import load_dotenv

# åŠ è½½ç¯å¢ƒå˜é‡
script_dir = os.path.dirname(os.path.abspath(__file__))
skill_root = os.path.dirname(os.path.dirname(script_dir))
load_dotenv(os.path.join(skill_root, '.env'))


class BingSearch:
    """Bing æœç´¢å®¢æˆ·ç«¯"""

    def __init__(self, proxy: Optional[str] = None):
        """
        åˆå§‹åŒ–å®¢æˆ·ç«¯

        Args:
            proxy: ä»£ç†åœ°å€ (å¦‚ http://127.0.0.1:7890)
        """
        self.proxy = proxy or os.getenv("BING_PROXY")
        self.session = requests.Session()
        # ä½¿ç”¨ç§»åŠ¨ç‰ˆ User-Agent ä»¥è·å–çº¯ HTML å“åº”
        self.session.headers.update({
            'User-Agent': 'Mozilla/5.0 (iPhone; CPU iPhone OS 16_0 like Mac OS X) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/16.0 Mobile/15E148 Safari/604.1',
            'Accept-Encoding': 'gzip, deflate'
        })
        if self.proxy:
            self.session.proxies = {'http': self.proxy, 'https': self.proxy}

    def _unwrap_bing_url(self, raw_url: str) -> Optional[str]:
        """è§£ç  Bing åŒ…è£…çš„ URL"""
        try:
            parsed = urlparse(raw_url)
            u_vals = parse_qs(parsed.query).get("u", [])
            if not u_vals:
                return raw_url
            u = u_vals[0]
            if len(u) <= 2:
                return raw_url
            b64_part = u[2:]
            padding = "=" * (-len(b64_part) % 4)
            decoded = base64.urlsafe_b64decode(b64_part + padding)
            return decoded.decode()
        except Exception:
            return raw_url

    def search(
        self,
        query: str,
        page: int = 1,
        lang: str = "en",
        country: str = "us",
        timelimit: Optional[str] = None,
        max_results: int = 10
    ) -> List[Dict[str, Any]]:
        """
        æ‰§è¡Œæœç´¢

        Args:
            query: æœç´¢å…³é”®è¯
            page: é¡µç 
            lang: è¯­è¨€ä»£ç  (é»˜è®¤: en)
            country: å›½å®¶ä»£ç  (é»˜è®¤: us)
            timelimit: æ—¶é—´é™åˆ¶ (d=å¤©, w=å‘¨, m=æœˆ, y=å¹´)
            max_results: æœ€å¤§ç»“æœæ•°

        Returns:
            æœç´¢ç»“æœåˆ—è¡¨
        """
        search_url = "https://www.bing.com/search"

        params = {
            "q": query,
            "pq": query,
            "cc": f"{lang}-{country}",
            "FORM": "QBRE"
        }

        if page > 1:
            params["first"] = str((page - 1) * 10)

        # æ—¶é—´é™åˆ¶è¿‡æ»¤å™¨
        if timelimit:
            time_map = {
                'd': 'ex1:"ez1"',
                'w': 'ex1:"ez2"',
                'm': 'ex1:"ez3"',
                'y': 'ex1:"ez5"'
            }
            params["filters"] = time_map.get(timelimit, '')

        # è®¾ç½® Cookie - æ·»åŠ æ›´å¤šå‚æ•°ä»¥è·å–çº¯ HTML ç‰ˆæœ¬
        cookies = {
            "_EDGE_CD": f"m={lang}-{country}&u={lang}-{country}",
            "_EDGE_S": f"mkt={lang}-{country}&ui={lang}-{country}",
            "SRCHD": "AF=NOFORM",
            "SRCHUID": "V=2",
            "_EDGE_V": "1",
            "MUID": "0",
        }

        # æ·»åŠ é¢å¤–çš„è¯·æ±‚å¤´ä»¥é¿å… JavaScript æ¸²æŸ“
        headers = {
            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
            'Accept-Language': f'{lang}-{country},{lang};q=0.9,en;q=0.8',
            'Cache-Control': 'max-age=0',
            'Upgrade-Insecure-Requests': '1',
        }

        try:
            response = self.session.get(
                search_url,
                params=params,
                cookies=cookies,
                headers=headers,
                timeout=15
            )
            response.raise_for_status()

            tree = html.fromstring(response.content)
            results = []

            # ä½¿ç”¨ XPath æå–ç»“æœ - ç§»åŠ¨ç‰ˆä½¿ç”¨ div è€Œä¸æ˜¯ li
            items = tree.xpath("//div[contains(@class, 'b_algo')]")

            for item in items[:max_results]:
                try:
                    # ç§»åŠ¨ç‰ˆç»“æ„: div.b_algo > div.b_algoheader > a > h2
                    title_elements = item.xpath(".//h2//text()")
                    href_elements = item.xpath(".//a/@href")
                    body_elements = item.xpath(".//p//text()")

                    if title_elements and href_elements:
                        title = ''.join(title_elements).strip()
                        href = self._unwrap_bing_url(href_elements[0])
                        body = ''.join(body_elements).strip()

                        if title and href:
                            results.append({
                                'title': title,
                                'href': href,
                                'body': body
                            })
                except Exception:
                    continue

            return results

        except Exception as e:
            raise Exception(f"Bing æœç´¢å¤±è´¥: {str(e)}")

    def format_results(self, results: List[Dict[str, Any]], query: str) -> str:
        """æ ¼å¼åŒ–æœç´¢ç»“æœ"""
        output = []
        output.append(f"ğŸ” Bing æœç´¢: {query}")
        output.append(f"ğŸ“Š æ‰¾åˆ° {len(results)} æ¡ç»“æœ")
        output.append("")

        for i, item in enumerate(results, 1):
            output.append(f"[{i}] {item.get('title', '')}")
            output.append(f"    ğŸ”— {item.get('href', '')}")
            if item.get('body'):
                output.append(f"    ğŸ“ {item.get('body', '')}")
            output.append("")

        return "\n".join(output)


def main():
    parser = argparse.ArgumentParser(description="Bing æœç´¢")
    parser.add_argument("query", help="æœç´¢å…³é”®è¯")
    parser.add_argument("-p", "--page", type=int, default=1, help="é¡µç  (é»˜è®¤: 1)")
    parser.add_argument("-m", "--max-results", type=int, default=10, help="æœ€å¤§ç»“æœæ•° (é»˜è®¤: 10)")
    parser.add_argument("-l", "--lang", default="en", help="è¯­è¨€ä»£ç  (é»˜è®¤: en)")
    parser.add_argument("-c", "--country", default="us", help="å›½å®¶ä»£ç  (é»˜è®¤: us)")
    parser.add_argument("-t", "--timelimit", choices=['d', 'w', 'm', 'y'], help="æ—¶é—´é™åˆ¶ (d=å¤©, w=å‘¨, m=æœˆ, y=å¹´)")
    parser.add_argument("--proxy", help="ä»£ç†åœ°å€")
    parser.add_argument("--json", action="store_true", help="JSON æ ¼å¼è¾“å‡º")
    parser.add_argument("--pretty", action="store_true", help="æ ¼å¼åŒ– JSON")

    args = parser.parse_args()

    try:
        client = BingSearch(proxy=args.proxy)
        results = client.search(
            query=args.query,
            page=args.page,
            lang=args.lang,
            country=args.country,
            timelimit=args.timelimit,
            max_results=args.max_results
        )

        if args.json:
            output_data = {
                'query': args.query,
                'page': args.page,
                'lang': args.lang,
                'country': args.country,
                'total_results': len(results),
                'results': results
            }
            if args.pretty:
                print(json.dumps(output_data, indent=2, ensure_ascii=False))
            else:
                print(json.dumps(output_data, ensure_ascii=False))
        else:
            print(client.format_results(results, args.query))

    except Exception as e:
        print(f"é”™è¯¯: {e}", file=sys.stderr)
        sys.exit(1)


if __name__ == "__main__":
    main()
