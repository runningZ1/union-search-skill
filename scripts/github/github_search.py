#!/usr/bin/env python3
"""
GitHub Search CLI - Search GitHub repositories, code, and issues

é›†æˆè‡ª github-search-skillï¼Œéµå¾ª union-search-skill çš„ä»£ç é£æ ¼
"""

import argparse
import json
import os
import sys
from datetime import datetime
from pathlib import Path
from typing import Any, Dict, List, Optional
import requests


# =============================================================================
# Exceptions
# =============================================================================

class GitHubSearchError(Exception):
    """Base exception for GitHub Search errors"""
    pass


class AuthenticationError(GitHubSearchError):
    """Raised when authentication fails"""
    pass


class RateLimitError(GitHubSearchError):
    """Raised when rate limit is exceeded"""
    pass


class ValidationError(GitHubSearchError):
    """Raised when query validation fails"""
    pass


# =============================================================================
# GitHub Search Client
# =============================================================================

class GitHubSearchClient:
    """Client for interacting with GitHub Search API"""

    BASE_URL = "https://api.github.com"
    API_VERSION = "2022-11-28"

    def __init__(self, token: Optional[str] = None):
        """
        Initialize GitHub Search Client

        Args:
            token: GitHub Personal Access Token (optional but recommended)
        """
        self.token = token
        self.session = requests.Session()

        if token:
            self.session.headers.update({
                "Authorization": f"Bearer {token}",
                "Accept": "application/vnd.github+json",
                "X-GitHub-Api-Version": self.API_VERSION,
                "User-Agent": "union-search-skill/1.0",
            })
        else:
            self.session.headers.update({
                "Accept": "application/vnd.github+json",
                "User-Agent": "union-search-skill/1.0",
            })

    def search_repositories(
        self,
        query: str,
        sort: Optional[str] = None,
        order: str = "desc",
        per_page: int = 30,
        max_results: int = 30,
    ) -> Dict[str, Any]:
        """Search for repositories"""
        endpoint = f"{self.BASE_URL}/search/repositories"
        params = {"q": query, "order": order, "per_page": min(per_page, 100)}
        if sort:
            params["sort"] = sort
        return self._search_with_pagination(endpoint, params, max_results)

    def search_code(
        self,
        query: str,
        sort: Optional[str] = None,
        order: str = "desc",
        per_page: int = 30,
        max_results: int = 30,
    ) -> Dict[str, Any]:
        """Search for code"""
        endpoint = f"{self.BASE_URL}/search/code"
        params = {"q": query, "order": order, "per_page": min(per_page, 100)}
        if sort:
            params["sort"] = sort
        return self._search_with_pagination(endpoint, params, max_results)

    def search_issues(
        self,
        query: str,
        sort: Optional[str] = None,
        order: str = "desc",
        per_page: int = 30,
        max_results: int = 30,
    ) -> Dict[str, Any]:
        """Search for issues and pull requests"""
        endpoint = f"{self.BASE_URL}/search/issues"
        params = {"q": query, "order": order, "per_page": min(per_page, 100)}
        if sort:
            params["sort"] = sort
        return self._search_with_pagination(endpoint, params, max_results)

    def get_rate_limit(self) -> Dict[str, Any]:
        """Get current rate limit status"""
        try:
            response = self.session.get(f"{self.BASE_URL}/rate_limit", timeout=30)
            response.raise_for_status()
            data = response.json()

            return {
                "search": {
                    "limit": data["resources"]["search"]["limit"],
                    "remaining": data["resources"]["search"]["remaining"],
                    "reset": datetime.fromtimestamp(data["resources"]["search"]["reset"]),
                    "used": data["resources"]["search"]["used"],
                },
                "core": {
                    "limit": data["resources"]["core"]["limit"],
                    "remaining": data["resources"]["core"]["remaining"],
                    "reset": datetime.fromtimestamp(data["resources"]["core"]["reset"]),
                    "used": data["resources"]["core"]["used"],
                },
            }
        except requests.exceptions.RequestException as e:
            raise GitHubSearchError(f"Failed to get rate limit: {str(e)}")

    def _search_with_pagination(
        self, endpoint: str, params: Dict[str, Any], max_results: int
    ) -> Dict[str, Any]:
        """Perform search with automatic pagination"""
        page = 1
        all_items = []
        total_count = 0
        incomplete_results = False

        max_results = min(max_results, 1000)

        while len(all_items) < max_results and page <= 10:
            params["page"] = page
            params["per_page"] = min(100, max_results - len(all_items))

            response = self._make_request(endpoint, params)
            data = self._handle_response(response)

            items = data.get("items", [])
            all_items.extend(items)
            total_count = data.get("total_count", 0)
            incomplete_results = data.get("incomplete_results", False)

            if len(items) < params["per_page"] or len(all_items) >= total_count:
                break

            page += 1

        return {
            "total_count": total_count,
            "incomplete_results": incomplete_results,
            "items": all_items,
        }

    def _make_request(self, endpoint: str, params: Dict[str, Any]) -> requests.Response:
        """Make HTTP request to GitHub API"""
        try:
            response = self.session.get(endpoint, params=params, timeout=30)
            return response
        except requests.exceptions.Timeout:
            raise GitHubSearchError("Request timed out")
        except requests.exceptions.ConnectionError:
            raise GitHubSearchError("Connection error. Please check your internet connection.")
        except requests.exceptions.RequestException as e:
            raise GitHubSearchError(f"Request failed: {str(e)}")

    def _handle_response(self, response: requests.Response) -> Dict[str, Any]:
        """Handle API response and errors"""
        if response.status_code == 200:
            return response.json()

        try:
            error_data = response.json()
            message = error_data.get("message", "Unknown error")
        except ValueError:
            message = response.text or f"HTTP {response.status_code}"

        if response.status_code == 401:
            raise AuthenticationError(f"Authentication failed: {message}")
        elif response.status_code == 403:
            if "rate limit" in message.lower():
                raise RateLimitError(f"Rate limit exceeded: {message}")
            raise GitHubSearchError(f"Forbidden: {message}")
        elif response.status_code == 422:
            raise ValidationError(f"Query validation failed: {message}")
        else:
            raise GitHubSearchError(f"API error ({response.status_code}): {message}")


# =============================================================================
# Output Formatters
# =============================================================================

def format_table(results: Dict[str, Any], resource_type: str) -> str:
    """Format results as a text table"""
    items = results.get("items", [])
    total_count = results.get("total_count", 0)

    if not items:
        return f"No results found. Total count: {total_count}"

    lines = []
    lines.append(f"{'='*80}")
    lines.append(f"GitHub {resource_type.capitalize()} Results")
    lines.append(f"Showing {len(items)} of {total_count} results")
    lines.append(f"{'='*80}\n")

    if resource_type == "repositories":
        for item in items:
            name = item.get("full_name", "N/A")
            stars = item.get("stargazers_count", 0)
            forks = item.get("forks_count", 0)
            language = item.get("language") or "N/A"
            description = item.get("description") or "No description"
            url = item.get("html_url", "")

            lines.append(f"ğŸ“¦ {name}")
            lines.append(f"   â­ {stars} | ğŸ´ {forks} | ğŸ’» {language}")
            lines.append(f"   ğŸ“ {description}")
            lines.append(f"   ğŸ”— {url}\n")

    elif resource_type == "code":
        for item in items:
            repo = item.get("repository", {})
            repo_name = repo.get("full_name", "N/A")
            file_path = item.get("path", "N/A")
            url = item.get("html_url", "")

            lines.append(f"ğŸ“„ {repo_name}")
            lines.append(f"   ğŸ“ {file_path}")
            lines.append(f"   ğŸ”— {url}\n")

    elif resource_type == "issues":
        for item in items:
            number = item.get("number", "N/A")
            title = item.get("title", "N/A")
            state = item.get("state", "N/A")
            comments = item.get("comments", 0)
            user = item.get("user", {})
            author = user.get("login", "N/A")
            url = item.get("html_url", "")
            item_type = "PR" if "pull_request" in item else "Issue"

            state_emoji = "ğŸŸ¢" if state == "open" else "ğŸ”´"
            lines.append(f"{state_emoji} #{number}: {title}")
            lines.append(f"   ğŸ“Œ {item_type} | ğŸ‘¤ @{author} | ğŸ’¬ {comments} comments")
            lines.append(f"   ğŸ”— {url}\n")

    return "\n".join(lines)


def format_json(results: Dict[str, Any]) -> str:
    """Format results as JSON"""
    return json.dumps(results, indent=2, ensure_ascii=False)


def format_markdown(results: Dict[str, Any], resource_type: str) -> str:
    """Format results as Markdown"""
    items = results.get("items", [])
    total_count = results.get("total_count", 0)

    if not items:
        return f"# GitHub Search Results\n\nNo results found. Total count: {total_count}"

    lines = [f"# GitHub Search Results\n"]
    lines.append(f"**Showing {len(items)} of {total_count} results**\n")

    if resource_type == "repositories":
        lines.append("## Repositories\n")
        for item in items:
            name = item.get("full_name", "N/A")
            stars = item.get("stargazers_count", 0)
            forks = item.get("forks_count", 0)
            language = item.get("language") or "N/A"
            description = item.get("description") or "No description"
            url = item.get("html_url", "")

            lines.append(f"### [{name}]({url})")
            lines.append(f"â­ {stars} | ğŸ´ {forks} | ğŸ’» {language}")
            lines.append(f"{description}\n")

    elif resource_type == "code":
        lines.append("## Code Files\n")
        for item in items:
            repo = item.get("repository", {})
            repo_name = repo.get("full_name", "N/A")
            file_path = item.get("path", "N/A")
            url = item.get("html_url", "")

            lines.append(f"### {repo_name}")
            lines.append(f"**File:** `{file_path}`")
            lines.append(f"**URL:** {url}\n")

    elif resource_type == "issues":
        lines.append("## Issues & Pull Requests\n")
        for item in items:
            number = item.get("number", "N/A")
            title = item.get("title", "N/A")
            state = item.get("state", "N/A")
            comments = item.get("comments", 0)
            user = item.get("user", {})
            author = user.get("login", "N/A")
            url = item.get("html_url", "")
            item_type = "Pull Request" if "pull_request" in item else "Issue"

            state_emoji = "ğŸŸ¢" if state == "open" else "ğŸ”´"
            lines.append(f"### {state_emoji} #{number}: {title}")
            lines.append(f"**Type:** {item_type} | **Author:** @{author} | **Comments:** {comments}")
            lines.append(f"**URL:** {url}\n")

    return "\n".join(lines)


def format_rate_limit(rate_limit_data: Dict[str, Any]) -> str:
    """Format rate limit information for display"""
    lines = []
    lines.append(f"{'='*70}")
    lines.append("GitHub API Rate Limit Status")
    lines.append(f"{'='*70}\n")

    for resource_name, resource_data in rate_limit_data.items():
        limit = resource_data.get("limit", "N/A")
        used = resource_data.get("used", "N/A")
        remaining = resource_data.get("remaining", "N/A")
        reset_time = resource_data.get("reset")
        reset_str = reset_time.strftime("%Y-%m-%d %H:%M:%S") if reset_time else "N/A"

        lines.append(f"{resource_name.capitalize()}:")
        lines.append(f"  Limit:     {limit}")
        lines.append(f"  Used:      {used}")
        lines.append(f"  Remaining: {remaining}")
        lines.append(f"  Resets At: {reset_str}\n")

    return "\n".join(lines)


# =============================================================================
# Response Archiving
# =============================================================================

def save_raw_response(data: Dict[str, Any], response_type: str, responses_dir: Path) -> str:
    """Save raw API response to file"""
    responses_dir.mkdir(parents=True, exist_ok=True)
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    filename = f"{timestamp}_{response_type}.json"
    filepath = responses_dir / filename

    with open(filepath, 'w', encoding='utf-8') as f:
        json.dump(data, f, indent=2, ensure_ascii=False)

    return str(filepath)


# =============================================================================
# Query Builder
# =============================================================================

def build_query(base_query: str, **filters) -> str:
    """Build GitHub search query from base query and filters"""
    query_parts = [base_query]

    for key, value in filters.items():
        if value is not None:
            if ' ' in str(value):
                query_parts.append(f'{key}:"{value}"')
            else:
                query_parts.append(f'{key}:{value}')

    return ' '.join(query_parts)


# =============================================================================
# CLI Main
# =============================================================================

def main():
    parser = argparse.ArgumentParser(
        description='GitHub Search CLI - Search repositories, code, and issues',
        formatter_class=argparse.RawTextHelpFormatter
    )

    # Global options
    parser.add_argument('--token', help='GitHub Personal Access Token (æˆ–ä½¿ç”¨ GITHUB_TOKEN ç¯å¢ƒå˜é‡)')

    subparsers = parser.add_subparsers(dest='command', help='æœç´¢å‘½ä»¤')

    # Common arguments for all search commands
    common_parser = argparse.ArgumentParser(add_help=False)
    common_parser.add_argument('--format', choices=['text', 'json', 'markdown'], default='text',
                               help='è¾“å‡ºæ ¼å¼ (é»˜è®¤: text)')
    common_parser.add_argument('--output', '-o', help='è¾“å‡ºæ–‡ä»¶è·¯å¾„')
    common_parser.add_argument('--save-raw', action='store_true',
                               help='ä¿å­˜åŸå§‹å“åº”åˆ° responses/ ç›®å½•')

    # Repository search
    repo_parser = subparsers.add_parser('repo', parents=[common_parser], help='æœç´¢ä»“åº“')
    repo_parser.add_argument('query', help='æœç´¢å…³é”®è¯')
    repo_parser.add_argument('--sort', choices=['stars', 'forks', 'help-wanted-issues', 'updated'],
                            help='æ’åºå­—æ®µ')
    repo_parser.add_argument('--order', choices=['asc', 'desc'], default='desc',
                            help='æ’åºé¡ºåº (é»˜è®¤: desc)')
    repo_parser.add_argument('--limit', type=int, default=30,
                            help='æœ€å¤§ç»“æœæ•° (é»˜è®¤: 30, æœ€å¤§: 1000)')
    repo_parser.add_argument('--language', help='æŒ‰ç¼–ç¨‹è¯­è¨€ç­›é€‰')
    repo_parser.add_argument('--user', help='æŒ‰ç”¨æˆ·/ç»„ç»‡ç­›é€‰')
    repo_parser.add_argument('--stars', help='æŒ‰æ˜Ÿæ ‡æ•°ç­›é€‰ (ä¾‹: ">1000", "100..500")')
    repo_parser.add_argument('--forks', help='æŒ‰åˆ†æ”¯æ•°ç­›é€‰')
    repo_parser.add_argument('--topic', help='æŒ‰ä¸»é¢˜ç­›é€‰')
    repo_parser.add_argument('--license', help='æŒ‰è®¸å¯è¯ç­›é€‰ (ä¾‹: "mit", "apache-2.0")')
    repo_parser.add_argument('--created', help='æŒ‰åˆ›å»ºæ—¥æœŸç­›é€‰ (ä¾‹: ">2020-01-01")')
    repo_parser.add_argument('--pushed', help='æŒ‰æœ€åæ¨é€æ—¥æœŸç­›é€‰')
    repo_parser.add_argument('--archived', choices=['true', 'false'],
                            help='æŒ‰å½’æ¡£çŠ¶æ€ç­›é€‰')

    # Code search
    code_parser = subparsers.add_parser('code', parents=[common_parser], help='æœç´¢ä»£ç ')
    code_parser.add_argument('query', help='æœç´¢å…³é”®è¯')
    code_parser.add_argument('--sort', choices=['indexed'],
                            help='æ’åºå­—æ®µ (ä»… "indexed" å¯ç”¨)')
    code_parser.add_argument('--order', choices=['asc', 'desc'], default='desc',
                            help='æ’åºé¡ºåº (é»˜è®¤: desc)')
    code_parser.add_argument('--limit', type=int, default=30,
                            help='æœ€å¤§ç»“æœæ•° (é»˜è®¤: 30, æœ€å¤§: 1000)')
    code_parser.add_argument('--language', help='æŒ‰ç¼–ç¨‹è¯­è¨€ç­›é€‰')
    code_parser.add_argument('--repo', help='æŒ‰ä»“åº“ç­›é€‰ (æ ¼å¼: owner/repo)')
    code_parser.add_argument('--user', help='æŒ‰ç”¨æˆ·/ç»„ç»‡ç­›é€‰')
    code_parser.add_argument('--path', help='æŒ‰æ–‡ä»¶è·¯å¾„ç­›é€‰')
    code_parser.add_argument('--extension', help='æŒ‰æ–‡ä»¶æ‰©å±•åç­›é€‰ (ä¾‹: "js", "py")')

    # Issue search
    issue_parser = subparsers.add_parser('issue', parents=[common_parser], help='æœç´¢é—®é¢˜å’Œ PR')
    issue_parser.add_argument('query', help='æœç´¢å…³é”®è¯')
    issue_parser.add_argument('--sort', choices=['comments', 'reactions', 'interactions', 'created', 'updated'],
                             help='æ’åºå­—æ®µ')
    issue_parser.add_argument('--order', choices=['asc', 'desc'], default='desc',
                             help='æ’åºé¡ºåº (é»˜è®¤: desc)')
    issue_parser.add_argument('--limit', type=int, default=30,
                             help='æœ€å¤§ç»“æœæ•° (é»˜è®¤: 30, æœ€å¤§: 1000)')
    issue_parser.add_argument('--repo', help='æŒ‰ä»“åº“ç­›é€‰ (æ ¼å¼: owner/repo)')
    issue_parser.add_argument('--user', help='æŒ‰ç”¨æˆ·/ç»„ç»‡ç­›é€‰')
    issue_parser.add_argument('--state', choices=['open', 'closed'],
                             help='æŒ‰çŠ¶æ€ç­›é€‰')
    issue_parser.add_argument('--author', help='æŒ‰ä½œè€…ç­›é€‰')
    issue_parser.add_argument('--assignee', help='æŒ‰å—è®©äººç­›é€‰')
    issue_parser.add_argument('--label', help='æŒ‰æ ‡ç­¾ç­›é€‰')
    issue_parser.add_argument('--milestone', help='æŒ‰é‡Œç¨‹ç¢‘ç­›é€‰')
    issue_parser.add_argument('--is-pr', action='store_true',
                             help='ä»…æ˜¾ç¤º Pull Request')
    issue_parser.add_argument('--is-issue', action='store_true',
                             help='ä»…æ˜¾ç¤º Issue')
    issue_parser.add_argument('--created', help='æŒ‰åˆ›å»ºæ—¥æœŸç­›é€‰ (ä¾‹: ">2020-01-01")')
    issue_parser.add_argument('--updated', help='æŒ‰æ›´æ–°æ—¥æœŸç­›é€‰')

    # Rate limit check
    subparsers.add_parser('rate-limit', help='æ£€æŸ¥ API é€Ÿç‡é™åˆ¶')

    args = parser.parse_args()

    if not args.command:
        parser.print_help()
        return 1

    # Get token from argument or environment
    token = args.token or os.environ.get('GITHUB_TOKEN')

    # Initialize client
    client = GitHubSearchClient(token)

    try:
        results = None
        resource_type = None

        # Execute command
        if args.command == 'repo':
            filters = {
                'language': args.language,
                'user': args.user,
                'stars': args.stars,
                'forks': args.forks,
                'topic': args.topic,
                'license': args.license,
                'created': args.created,
                'pushed': args.pushed,
                'archived': args.archived,
            }
            query = build_query(args.query, **filters)
            results = client.search_repositories(
                query=query,
                sort=args.sort,
                order=args.order,
                max_results=args.limit
            )
            resource_type = 'repositories'

        elif args.command == 'code':
            filters = {
                'language': args.language,
                'repo': args.repo,
                'user': args.user,
                'path': args.path,
                'extension': args.extension,
            }
            query = build_query(args.query, **filters)
            results = client.search_code(
                query=query,
                sort=args.sort,
                order=args.order,
                max_results=args.limit
            )
            resource_type = 'code'

        elif args.command == 'issue':
            filters = {
                'repo': args.repo,
                'user': args.user,
                'state': args.state,
                'author': args.author,
                'assignee': args.assignee,
                'label': args.label,
                'milestone': args.milestone,
                'created': args.created,
                'updated': args.updated,
            }
            if args.is_pr:
                filters['type'] = 'pr'
            elif args.is_issue:
                filters['type'] = 'issue'
            else:
                filters['type'] = 'issue'
            query = build_query(args.query, **filters)
            results = client.search_issues(
                query=query,
                sort=args.sort,
                order=args.order,
                max_results=args.limit
            )
            resource_type = 'issues'

        elif args.command == 'rate-limit':
            rate_limit_data = client.get_rate_limit()
            output = format_rate_limit(rate_limit_data)
            print(output)
            return 0

        # Save raw response if requested
        if args.save_raw and results:
            script_dir = Path(__file__).parent.parent
            responses_dir = script_dir / 'responses'
            filepath = save_raw_response(results, f'github_{args.command}', responses_dir)
            print(f"[åŸå§‹å“åº”å·²ä¿å­˜åˆ°: {filepath}]\n", file=sys.stderr)

        # Format output
        if args.format == 'json':
            output = format_json(results)
        elif args.format == 'markdown':
            output = format_markdown(results, resource_type)
        else:  # text
            output = format_table(results, resource_type)

        # Write to file or stdout
        if args.output:
            with open(args.output, 'w', encoding='utf-8') as f:
                f.write(output)
            print(f"ç»“æœå·²ä¿å­˜åˆ°: {args.output}")
        else:
            print(output)

        return 0

    except GitHubSearchError as e:
        print(f"é”™è¯¯: {e}", file=sys.stderr)
        return 1
    except Exception as e:
        print(f"æœªçŸ¥é”™è¯¯: {e}", file=sys.stderr)
        return 1


if __name__ == "__main__":
    sys.exit(main())
