"""è·å–è§†é¢‘å®Œæ•´æ•°æ®ï¼ˆæ— éœ€ç™»å½•ï¼‰"""

import asyncio
import json
from datetime import datetime
from pathlib import Path
from typing import Dict

from bilibili_api import video

try:
    from .utils import print_header
except ImportError:
    from utils import print_header


async def get_all_video_data(bvid: str) -> Dict:
    """è·å–è§†é¢‘çš„æ‰€æœ‰æ•°æ®"""
    print_header(f"å¼€å§‹è·å–è§†é¢‘æ•°æ®ï¼š{bvid}")

    v = video.Video(bvid=bvid)
    data = {"bvid": bvid, "fetch_time": datetime.now().isoformat()}

    # 1. åŸºæœ¬ä¿¡æ¯
    print("\nğŸ“º è·å–åŸºæœ¬ä¿¡æ¯...")
    info = await v.get_info()
    data["basic_info"] = {
        "title": info.get("title"),
        "aid": info.get("aid"),
        "desc": info.get("desc"),
        "pubdate": info.get("pubdate"),
        "pubdate_formatted": datetime.fromtimestamp(info.get("pubdate", 0)).strftime("%Y-%m-%d %H:%M:%S"),
        "duration": info.get("duration"),
        "owner": {
            "mid": info.get("owner", {}).get("mid"),
            "name": info.get("owner", {}).get("name"),
            "face": info.get("owner", {}).get("face")
        },
        "pic": info.get("pic"),
        "cid": info.get("cid")
    }
    print(f"  æ ‡é¢˜ï¼š{data['basic_info']['title']}")
    print(f"  UP ä¸»ï¼š{data['basic_info']['owner']['name']}")

    # 2. ç»Ÿè®¡æ•°æ®
    print("\nğŸ“Š è·å–ç»Ÿè®¡æ•°æ®...")
    stat = info.get("stat", {})
    data["statistics"] = {
        "view": stat.get("view", 0),
        "danmaku": stat.get("danmaku", 0),
        "reply": stat.get("reply", 0),
        "favorite": stat.get("favorite", 0),
        "coin": stat.get("coin", 0),
        "share": stat.get("share", 0),
        "like": stat.get("like", 0)
    }
    print(f"  æ’­æ”¾ï¼š{data['statistics']['view']:,} | ç‚¹èµï¼š{data['statistics']['like']:,}")

    # 3. åˆ† P ä¿¡æ¯
    print("\nğŸ¬ è·å–åˆ† P ä¿¡æ¯...")
    data["pages"] = []
    for idx, page in enumerate(await v.get_pages(), 1):
        page_info = {
            "page": idx,
            "cid": page.get("cid"),
            "part": page.get("part"),
            "duration": page.get("duration"),
            "duration_formatted": f"{page.get('duration') // 60}:{page.get('duration') % 60:02d}"
        }
        data["pages"].append(page_info)
        print(f"  P{idx}: {page_info['part']} ({page_info['duration_formatted']})")

    # 4. æ ‡ç­¾
    print("\nğŸ·ï¸ è·å–æ ‡ç­¾...")
    data["tags"] = []
    for tag in await v.get_tags():
        data["tags"].append({"tag_id": tag.get("tag_id"), "tag_name": tag.get("tag_name")})
    print(f"  å…± {len(data['tags'])} ä¸ªæ ‡ç­¾ï¼š{', '.join([t['tag_name'] for t in data['tags']])}")

    # 5. å­—å¹•
    print("\nğŸ’¬ è·å–å­—å¹•...")
    data["subtitles"] = []
    try:
        cid = data["basic_info"]["cid"]
        if cid:
            subtitle_data = await v.get_subtitle(cid=cid)
            if subtitle_data:
                subtitle_list = subtitle_data.get("subtitles", []) if isinstance(subtitle_data, dict) else subtitle_data
                for sub in subtitle_list:
                    data["subtitles"].append({
                        "id": sub.get("id"),
                        "lan": sub.get("lan"),
                        "lan_doc": sub.get("lan_doc"),
                        "subtitle_url": sub.get("subtitle_url")
                    })
                print(f"  å…± {len(data['subtitles'])} ä¸ªå­—å¹•")
            else:
                print("  æ— å­—å¹•")
    except Exception as e:
        print(f"  è·å–å­—å¹•å¤±è´¥ï¼š{e}")

    # 6. ç›¸å…³æ¨è
    print("\nğŸ”— è·å–ç›¸å…³æ¨è...")
    data["related_videos"] = []
    try:
        related = await v.get_related()
        for rel in related[:10]:
            data["related_videos"].append({
                "bvid": rel.get("bvid"),
                "title": rel.get("title"),
                "owner": {"mid": rel.get("owner", {}).get("mid"), "name": rel.get("owner", {}).get("name")},
                "stat": {"view": rel.get("stat", {}).get("view"), "danmaku": rel.get("stat", {}).get("danmaku")}
            })
        print(f"  è·å–åˆ° {len(data['related_videos'])} ä¸ªç›¸å…³æ¨è")
    except Exception as e:
        print(f"  è·å–ç›¸å…³æ¨èå¤±è´¥ï¼š{e}")

    # 7. å¼¹å¹•
    print("\nğŸ’¥ è·å–å¼¹å¹•...")
    data["danmaku_count"] = 0
    data["danmakus_sample"] = []
    try:
        danmakus = await v.get_danmakus()
        data["danmaku_count"] = len(danmakus)
        for dm in danmakus[:20]:
            data["danmakus_sample"].append({
                "text": dm.text,
                "dm_time": dm.dm_time,
                "time_position": f"{dm.dm_time / 1000:.1f}s" if dm.dm_time else "0.0s",
                "send_time": dm.send_time,
                "send_time_formatted": datetime.fromtimestamp(dm.send_time).strftime("%Y-%m-%d %H:%M:%S") if dm.send_time else "",
                "sender_id": dm.uid,
                "color": dm.color,
                "font_size": dm.font_size,
                "mode": dm.mode
            })
        print(f"  å…± {data['danmaku_count']} æ¡å¼¹å¹• (å·²è®°å½•å‰ 20 æ¡)")
    except Exception as e:
        print(f"  è·å–å¼¹å¹•å¤±è´¥ï¼š{e}")

    print("\n" + "=" * 60)
    print("âœ… æ‰€æœ‰æ•°æ®è·å–å®Œæˆï¼")
    return data


def save_to_json(data: Dict, output_file: str = None) -> str:
    """ä¿å­˜ä¸º JSON"""
    if output_file is None:
        output_file = f"video_data_{data['bvid']}.json"
    output_path = Path(output_file)
    with open(output_path, "w", encoding="utf-8") as f:
        json.dump(data, f, ensure_ascii=False, indent=2)
    print(f"\nğŸ’¾ JSON å·²ä¿å­˜ï¼š{output_path.absolute()}")
    return str(output_path.absolute())


def save_to_markdown(data: Dict, output_file: str = None) -> str:
    """ä¿å­˜ä¸º Markdown"""
    if output_file is None:
        output_file = f"video_data_{data['bvid']}.md"
    output_path = Path(output_file)

    bi = data['basic_info']
    stats = data['statistics']

    md_lines = [
        "# B ç«™è§†é¢‘æ•°æ®æŠ¥å‘Š\n",
        f"**BVID**: {data['bvid']}\n",
        f"**è·å–æ—¶é—´**: {datetime.fromisoformat(data['fetch_time']).strftime('%Y-%m-%d %H:%M:%S')}\n",
        "\n---\n",
        "## ğŸ“º åŸºæœ¬ä¿¡æ¯\n",
        f"- **æ ‡é¢˜**: {bi['title']}\n",
        f"- **AV å·**: {bi['aid']}\n",
        f"- **UP ä¸»**: [{bi['owner']['name']}](https://space.bilibili.com/{bi['owner']['mid']})\n",
        f"- **å‘å¸ƒæ—¶é—´**: {bi['pubdate_formatted']}\n",
        f"- **æ—¶é•¿**: {bi['duration']}ç§’\n",
        f"- **ç®€ä»‹**: {bi['desc']}\n",
        "\n---\n",
        "## ğŸ“Š æ•°æ®ç»Ÿè®¡\n",
        "| æŒ‡æ ‡ | æ•°å€¼ |\n|------|------|\n",
        f"| æ’­æ”¾é‡ | {stats['view']:,} |\n",
        f"| ç‚¹èµæ•° | {stats['like']:,} |\n",
        f"| æŠ•å¸æ•° | {stats['coin']:,} |\n",
        f"| æ”¶è—æ•° | {stats['favorite']:,} |\n",
        f"| åˆ†äº«æ•° | {stats['share']:,} |\n",
        f"| å¼¹å¹•æ•° | {stats['danmaku']:,} |\n",
        f"| è¯„è®ºæ•° | {stats['reply']:,} |\n",
        "\n---\n",
        "## ğŸ¬ åˆ† P ä¿¡æ¯\n"
    ]

    for page in data["pages"]:
        md_lines.append(f"\n### P{page['page']}: {page['part']}\n")
        md_lines.append(f"- CID: {page['cid']}\n")
        md_lines.append(f"- æ—¶é•¿ï¼š{page['duration_formatted']}\n")

    md_lines.extend(["\n---\n", "## ğŸ·ï¸ æ ‡ç­¾\n"])
    for tag in data["tags"]:
        md_lines.append(f"- {tag['tag_name']}\n")

    if data.get("subtitles"):
        md_lines.extend(["\n---\n", "## ğŸ’¬ å­—å¹•\n"])
        for sub in data["subtitles"]:
            md_lines.append(f"- {sub['lan_doc']}: {sub['subtitle_url']}\n")

    if data.get("related_videos"):
        md_lines.extend(["\n---\n", "## ğŸ”— ç›¸å…³æ¨è\n"])
        for rel in data["related_videos"]:
            md_lines.append(f"\n#### [{rel['title']}](https://www.bilibili.com/video/{rel['bvid']})\n")
            md_lines.append(f"- UP ä¸»ï¼š{rel['owner']['name']}\n")
            md_lines.append(f"- æ’­æ”¾ï¼š{rel['stat']['view']:,}\n")

    if data.get("danmaku_count", 0) > 0:
        md_lines.extend(["\n---\n", f"## ğŸ’¥ å¼¹å¹• (å…±{data['danmaku_count']:,}æ¡ï¼Œæ˜¾ç¤ºå‰ 20 æ¡)\n"])
        for dm in data["danmakus_sample"]:
            md_lines.append(f"- [{dm.get('time_position', '')}] {dm['text']}\n")

    md_lines.append(f"\n---\n\n*æŠ¥å‘Šç”Ÿæˆæ—¶é—´ï¼š{data['fetch_time']}*\n")

    with open(output_path, "w", encoding="utf-8") as f:
        f.writelines(md_lines)
    print(f"ğŸ“ Markdown å·²ä¿å­˜ï¼š{output_path.absolute()}")
    return str(output_path.absolute())


async def main():
    """å‘½ä»¤è¡Œå…¥å£"""
    import sys

    bvid = sys.argv[1].strip() if len(sys.argv) > 1 else input("è¯·è¾“å…¥è§†é¢‘ BVID: ").strip()
    data = await get_all_video_data(bvid)
    json_file = save_to_json(data)
    md_file = save_to_markdown(data)
    print(f"\nğŸ‰ å®Œæˆï¼\n  - JSON: {json_file}\n  - Markdown: {md_file}")


if __name__ == "__main__":
    asyncio.run(main())
