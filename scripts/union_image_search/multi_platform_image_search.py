#!/usr/bin/env python3
"""
Multi-Platform Image Search and Download Script
å®Œå…¨ç‹¬ç«‹çš„å…¨å¹³å°å›¾ç‰‡æœç´¢ä¸‹è½½è„šæœ¬

æ”¯æŒ 18 ä¸ªå›¾ç‰‡å¹³å°çš„æ‰¹é‡æœç´¢å’Œä¸‹è½½ (æ–°å¢ç«å±±å¼•æ“)
ä¾èµ–: pip install pyimagedl
"""

import argparse
import json
import os
import sys
import time
from datetime import datetime
from pathlib import Path

# æ£€æŸ¥ä¾èµ–
try:
    from imagedl import imagedl
except ImportError:
    print("é”™è¯¯ï¼šæœªå®‰è£… pyimagedl åŒ…", file=sys.stderr)
    print("è¯·è¿è¡Œï¼špip install pyimagedl", file=sys.stderr)
    sys.exit(1)

# æ”¯æŒçš„æ‰€æœ‰å¹³å°é…ç½®
SUPPORTED_PLATFORMS = {
    'baidu': 'BaiduImageClient',
    'bing': 'BingImageClient',
    'google': 'GoogleImageClient',
    'i360': 'I360ImageClient',
    'pixabay': 'PixabayImageClient',
    'yandex': 'YandexImageClient',
    'sogou': 'SogouImageClient',
    'yahoo': 'YahooImageClient',
    'unsplash': 'UnsplashImageClient',
    'gelbooru': 'GelbooruImageClient',
    'safebooru': 'SafebooruImageClient',
    'danbooru': 'DanbooruImageClient',
    'pexels': 'PexelsImageClient',
    'huaban': 'HuabanImageClient',
    'foodiesfeed': 'FoodiesfeedImageClient',
    'volcengine': 'VolcengineAdapter',  # ç«å±±å¼•æ“ (API-based)
}

DEFAULT_SAVE_SUFFIX = "image_search_results"
UNLIMITED_SEARCH_LIMIT = 10000


def load_env_file(path):
    """åŠ è½½ç¯å¢ƒå˜é‡æ–‡ä»¶"""
    if not path or not os.path.exists(path):
        return

    with open(path, "r", encoding="utf-8") as f:
        for line in f:
            line = line.strip()
            if not line or line.startswith("#") or "=" not in line:
                continue

            key, value = line.split("=", 1)
            key = key.strip()
            value = value.strip()

            if key and key not in os.environ:
                os.environ[key] = value


def get_env_int(name, default):
    """è·å–æ•´æ•°ç¯å¢ƒå˜é‡"""
    value = os.getenv(name)
    if not value:
        return default

    try:
        return int(value)
    except ValueError:
        return default


def get_env_str(name, default):
    """è·å–å­—ç¬¦ä¸²ç¯å¢ƒå˜é‡"""
    value = os.getenv(name)
    return value if value else default


def extract_env_file_from_argv(argv):
    """ä»å‘½ä»¤è¡Œå‚æ•°è·å–ç¯å¢ƒå˜é‡æ–‡ä»¶è·¯å¾„"""
    for i, arg in enumerate(argv):
        if arg == "--env-file" and i + 1 < len(argv):
            return argv[i + 1]
        if arg.startswith("--env-file="):
            return arg.split("=", 1)[1]
    return ".env"


def parse_args():
    """è§£æå‘½ä»¤è¡Œå‚æ•°"""
    examples = (
        "Examples:\n"
        "  python multi_platform_image_search.py \"cute cats\" --num 50\n"
        "  python multi_platform_image_search.py --keyword \"sunset\" --platforms baidu google pixabay\n"
        "  python multi_platform_image_search.py --keyword \"flowers\" --output ./my_images --num 100\n"
        "  python multi_platform_image_search.py --list-platforms\n"
    )
    parser = argparse.ArgumentParser(
        description="Multi-platform image search and download tool",
        formatter_class=argparse.RawTextHelpFormatter,
        epilog=examples,
    )
    parser.add_argument("--env-file", default=extract_env_file_from_argv(sys.argv), help="Env file path")
    parser.add_argument("keyword", nargs="?", help="Search keyword (positional)")
    parser.add_argument("--keyword", dest="keyword_opt", help="Search keyword (overrides positional)")
    parser.add_argument("--platforms", nargs="+", choices=list(SUPPORTED_PLATFORMS.keys()),
                       help="Specify platform list (default: all platforms)")
    parser.add_argument("--num", type=int, help="Images per platform, <=0 means unlimited (default: 10)")
    parser.add_argument("--output", help="Output directory (default: image_downloads)")
    parser.add_argument("--threads", type=int, help="Download threads (default: 5)")
    parser.add_argument("--no-metadata", action="store_true", help="Don't save metadata")
    parser.add_argument("--delay", type=float, help="Delay between platforms in seconds (default: 1.0)")
    parser.add_argument("--list-platforms", action="store_true", help="List all supported platforms")
    parser.add_argument("--pretty", action="store_true", help="Pretty-print JSON output")
    return parser.parse_args()


def apply_env_defaults(args):
    """åº”ç”¨ç¯å¢ƒå˜é‡é»˜è®¤å€¼"""
    args.keyword = args.keyword_opt or args.keyword or get_env_str("IMAGE_SEARCH_KEYWORD", "")

    if args.platforms is None:
        platforms_str = get_env_str("IMAGE_SEARCH_PLATFORMS", "")
        args.platforms = platforms_str.split(",") if platforms_str else None

    if args.num is None:
        args.num = get_env_int("IMAGE_SEARCH_NUM", 10)

    if args.output is None:
        args.output = get_env_str("IMAGE_SEARCH_OUTPUT", "image_downloads")

    if args.threads is None:
        args.threads = get_env_int("IMAGE_SEARCH_THREADS", 5)

    if args.delay is None:
        args.delay = float(get_env_str("IMAGE_SEARCH_DELAY", "1.0"))

    return args


def count_downloaded_images(directory):
    """ç»Ÿè®¡ç›®å½•ä¸­ä¸‹è½½çš„å›¾ç‰‡æ•°é‡"""
    if not os.path.exists(directory):
        return 0

    image_extensions = ('.jpg', '.jpeg', '.png', '.gif', '.webp', '.bmp', '.tiff')
    count = 0

    for root, _, files in os.walk(directory):
        count += sum(1 for f in files if f.lower().endswith(image_extensions))

    return count


def save_metadata(platform_dir, platform, keyword, image_infos):
    """ä¿å­˜å…ƒæ•°æ®åˆ° JSON æ–‡ä»¶"""
    metadata = {
        'platform': platform,
        'keyword': keyword,
        'timestamp': datetime.now().isoformat(),
        'total_images': len(image_infos),
        'images': [
            {
                'index': idx,
                'identifier': info.get('identifier', ''),
                'urls': info.get('candidate_urls', []),
                'file_path': info.get('file_path', ''),
                'raw_data': info.get('raw_data', {})
            }
            for idx, info in enumerate(image_infos, 1)
        ]
    }

    metadata_file = os.path.join(platform_dir, 'metadata.json')
    with open(metadata_file, 'w', encoding='utf-8') as f:
        json.dump(metadata, f, ensure_ascii=False, indent=2)

    return metadata_file


def create_error_result(platform, keyword, error, output_dir=None):
    """åˆ›å»ºé”™è¯¯ç»“æœå­—å…¸"""
    return {
        'platform': platform,
        'keyword': keyword,
        'success': False,
        'error': error,
        'downloaded': 0,
        'metadata': [],
        'output_dir': output_dir or ''
    }


def search_platform(platform, keyword, num_images, output_dir, num_threads, save_meta):
    """åœ¨å•ä¸ªå¹³å°æœç´¢å›¾ç‰‡"""
    if platform not in SUPPORTED_PLATFORMS:
        return create_error_result(platform, keyword, f'ä¸æ”¯æŒçš„å¹³å°: {platform}')

    # ç«å±±å¼•æ“ä½¿ç”¨ç‹¬ç«‹çš„é€‚é…å™¨
    if platform == 'volcengine':
        try:
            # å¯¼å…¥ç«å±±å¼•æ“é€‚é…å™¨
            sys.path.insert(0, str(Path(__file__).parent))
            from volcengine_adapter import search_volcengine_images
            return search_volcengine_images(keyword, num_images, output_dir, num_threads, save_meta)
        except ImportError as e:
            return create_error_result(platform, keyword, f'ç«å±±å¼•æ“é€‚é…å™¨å¯¼å…¥å¤±è´¥: {e}')
        except Exception as e:
            return create_error_result(platform, keyword, str(e))

    platform_client_name = SUPPORTED_PLATFORMS[platform]
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    safe_keyword = keyword.replace(' ', '_').replace('/', '_')
    platform_dir = os.path.join(output_dir, f"{platform}_{safe_keyword}_{timestamp}")

    target_text = "ä¸é™åˆ¶" if num_images <= 0 else f"{num_images} å¼ "
    print(f"\n{'='*70}")
    print(f"å¹³å°: {platform.upper()} | å…³é”®è¯: '{keyword}' | ç›®æ ‡: {target_text}")
    print(f"{'='*70}")

    try:
        search_limits = UNLIMITED_SEARCH_LIMIT if num_images <= 0 else num_images

        client = imagedl.ImageClient(
            image_source=platform_client_name,
            init_image_client_cfg={'work_dir': platform_dir},
            search_limits=search_limits,
            num_threadings=num_threads
        )

        print(f"[1/2] æ­£åœ¨æœç´¢...")
        search_limits_overrides = UNLIMITED_SEARCH_LIMIT if num_images <= 0 else num_images
        image_infos = client.search(
            keyword,
            search_limits_overrides=search_limits_overrides,
            num_threadings_overrides=num_threads
        )

        if not image_infos:
            print(f"âœ— æœªæ‰¾åˆ°å›¾ç‰‡")
            return create_error_result(platform, keyword, 'æœªæ‰¾åˆ°å›¾ç‰‡', platform_dir)

        # æŸäº›å¹³å°ä¼šå¿½ç•¥ search_limitsï¼Œè¿”å›è¿œè¶…é¢„æœŸçš„æ•°æ®é‡ï¼›åœ¨è¿™é‡ŒæŒ‰ --num å¼ºåˆ¶æˆªæ–­ï¼Œ
        # ä½†å½“ --num <= 0 æ—¶ä¸é™åˆ¶ä¸‹è½½æ•°é‡ã€‚
        found_count = len(image_infos)
        print(f"âœ“ æ‰¾åˆ° {found_count} å¼ å›¾ç‰‡")

        if num_images > 0 and found_count > num_images:
            image_infos = image_infos[:num_images]
            print(f"â„¹ é™åˆ¶ä¸‹è½½æ•°é‡ä¸º {num_images} å¼  (æŒ‰ --num å‚æ•°)")

        print(f"[2/2] æ­£åœ¨ä¸‹è½½...")
        client.download(
            image_infos=image_infos,
            num_threadings_overrides=num_threads
        )

        downloaded_count = count_downloaded_images(platform_dir)
        metadata_file = None

        if save_meta and image_infos:
            metadata_file = save_metadata(platform_dir, platform, keyword, image_infos)

        print(f"âœ“ æˆåŠŸä¸‹è½½ {downloaded_count} å¼ å›¾ç‰‡")
        print(f"âœ“ ä¿å­˜ä½ç½®: {platform_dir}")

        return {
            'platform': platform,
            'keyword': keyword,
            'success': True,
            'downloaded': downloaded_count,
            'found': found_count,
            'metadata': image_infos,
            'output_dir': platform_dir,
            'metadata_file': metadata_file
        }

    except Exception as e:
        print(f"âœ— é”™è¯¯: {str(e)}")
        return create_error_result(platform, keyword, str(e), platform_dir)


def search_all_platforms(keyword, num_images, platforms, output_dir, num_threads, save_meta, delay):
    """åœ¨æ‰€æœ‰å¹³å°æœç´¢å›¾ç‰‡"""
    platforms = platforms or list(SUPPORTED_PLATFORMS.keys())

    print(f"\n{'='*70}")
    print(f"å¤šå¹³å°å›¾ç‰‡æœç´¢")
    print(f"{'='*70}")
    print(f"å…³é”®è¯: {keyword}")
    print(f"å¹³å°æ•°: {len(platforms)}")
    per_platform_text = "ä¸é™åˆ¶" if num_images <= 0 else f"{num_images} å¼ "
    print(f"æ¯å¹³å°: {per_platform_text}")
    print(f"è¾“å‡ºç›®å½•: {output_dir}")
    print(f"{'='*70}\n")

    results = {
        'keyword': keyword,
        'total_platforms': len(platforms),
        'timestamp': datetime.now().isoformat(),
        'platforms': []
    }

    for i, platform in enumerate(platforms, 1):
        print(f"\n[{i}/{len(platforms)}] å¤„ç†å¹³å°: {platform.upper()}")
        result = search_platform(platform, keyword, num_images, output_dir, num_threads, save_meta)
        results['platforms'].append(result)

        if i < len(platforms):
            time.sleep(delay)

    return results


def print_summary(results):
    """æ‰“å°æœç´¢æ€»ç»“"""
    successful = [p for p in results['platforms'] if p['success']]
    failed = [p for p in results['platforms'] if not p['success']]
    total_images = sum(p['downloaded'] for p in successful)

    print(f"\n{'='*70}")
    print(f"æœç´¢å®Œæˆï¼")
    print(f"{'='*70}\n")

    print(f"âœ… æˆåŠŸçš„å¹³å° ({len(successful)}/{results['total_platforms']}):")
    for p in successful:
        print(f"  - {p['platform']:15s}: {p['downloaded']:3d} å¼  (æ‰¾åˆ° {p.get('found', 0)} å¼ )")

    if failed:
        print(f"\nâŒ å¤±è´¥çš„å¹³å° ({len(failed)}/{results['total_platforms']}):")
        for p in failed:
            error = p['error'][:60]
            print(f"  - {p['platform']:15s}: {error}")

    print(f"\nğŸ“Š æ€»è®¡:")
    print(f"  - æˆåŠŸå¹³å°: {len(successful)}")
    print(f"  - å¤±è´¥å¹³å°: {len(failed)}")
    print(f"  - æ€»ä¸‹è½½å›¾ç‰‡: {total_images} å¼ ")
    if results['total_platforms'] > 0:
        print(f"  - æˆåŠŸç‡: {len(successful)*100//results['total_platforms']}%")

    print(f"\n{'='*70}\n")


def save_summary(results, base_dir):
    """ä¿å­˜æœç´¢æ€»ç»“æŠ¥å‘Š"""
    save_dir = os.path.join(base_dir, "responses")
    os.makedirs(save_dir, exist_ok=True)

    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    filename = f"{timestamp}_{DEFAULT_SAVE_SUFFIX}.json"
    save_path = os.path.join(save_dir, filename)

    simplified_results = {
        'keyword': results['keyword'],
        'total_platforms': results['total_platforms'],
        'timestamp': results['timestamp'],
        'platforms': [
            {
                'platform': p['platform'],
                'keyword': p['keyword'],
                'success': p['success'],
                'downloaded': p['downloaded'],
                'found': p.get('found', 0),
                'error': p.get('error', ''),
                'output_dir': p['output_dir'],
                'metadata_file': p.get('metadata_file', '')
            }
            for p in results['platforms']
        ]
    }

    with open(save_path, 'w', encoding='utf-8') as f:
        json.dump(simplified_results, f, ensure_ascii=False, indent=2)

    return save_path


def main():
    """ä¸»å‡½æ•°"""
    env_file = extract_env_file_from_argv(sys.argv)
    load_env_file(env_file)
    args = apply_env_defaults(parse_args())

    if args.list_platforms:
        print("\næ”¯æŒçš„å¹³å°åˆ—è¡¨:")
        print("="*50)
        for short_name, full_name in SUPPORTED_PLATFORMS.items():
            print(f"  {short_name:15s} -> {full_name}")
        print("="*50)
        print(f"æ€»è®¡: {len(SUPPORTED_PLATFORMS)} ä¸ªå¹³å°\n")
        return 0

    if not args.keyword:
        print("é”™è¯¯ï¼šå¿…é¡»æŒ‡å®šæœç´¢å…³é”®è¯", file=sys.stderr)
        print("ä½¿ç”¨ --keyword å‚æ•°æˆ–ä½ç½®å‚æ•°æä¾›å…³é”®è¯", file=sys.stderr)
        return 2

    os.makedirs(args.output, exist_ok=True)

    results = search_all_platforms(
        keyword=args.keyword,
        num_images=args.num,
        platforms=args.platforms,
        output_dir=args.output,
        num_threads=args.threads,
        save_meta=not args.no_metadata,
        delay=args.delay
    )

    print_summary(results)

    base_dir = os.path.dirname(os.path.abspath(__file__))
    save_path = save_summary(results, base_dir)

    successful_platforms = [p for p in results['platforms'] if p['success']]
    output = {
        'saved_to': save_path,
        'summary': {
            'keyword': results['keyword'],
            'total_platforms': results['total_platforms'],
            'successful': len(successful_platforms),
            'failed': results['total_platforms'] - len(successful_platforms),
            'total_images': sum(p['downloaded'] for p in successful_platforms)
        },
        'platforms': results['platforms']
    }

    if args.pretty:
        print(json.dumps(output, indent=2, ensure_ascii=False))
    else:
        print(json.dumps(output, ensure_ascii=False))

    print(f"\nâœ“ æœç´¢æŠ¥å‘Šå·²ä¿å­˜: {save_path}")
    return 0


if __name__ == "__main__":
    raise SystemExit(main())
